{
  "checkpoints": [
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_cl_agent_on_val_tasks\",\n  \"trial_id\": \"c9af6_00002\",\n  \"config\": {\n    \"generic\": {\n      \"lr\": 0.001,\n      \"lradj\": \"step15\",\n      \"batch_size\": 32,\n      \"weight_decay\": 0\n    },\n    \"model\": {\n      \"feature_dim\": 128,\n      \"n_layers\": 4,\n      \"dropout\": 0\n    },\n    \"agent\": {}\n  },\n  \"_local_dir\": \"/disk2/lihuajian/TSCIL/result/ray_tune_results/class/har/CNN_BN_ER\",\n  \"evaluated_params\": {\n    \"generic/lradj\": \"step15\"\n  },\n  \"experiment_tag\": \"2_lradj=step15\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740100000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"end_avg_acc\": 80.18166666666667,\n    \"end_avg_fgt\": 25.97,\n    \"avg_cur_acc\": 97.495,\n    \"Acc_across_runs\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059507010000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d6275666665729493942896900000000000000000000000000059400000000000000000000000000000000066666666669656400000000000005940000000000000000033333333330358400000000000004a403333333333e355400000000000005940000000000000000000000000000000007b14ae47e1ea5640000000000000594000000000000000000000000000905840295c8fc2f5e848407b14ae47e15a5840948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b024b034b0387948c014394749452942e\"\n    },\n    \"time_this_iter_s\": 244.96328997612,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"c9af6_00002\",\n    \"experiment_id\": \"a456c96e0feb4f67b5876a0f260d5776\",\n    \"date\": \"2024-05-06_15-44-48\",\n    \"timestamp\": 1714981488,\n    \"time_total_s\": 244.96328997612,\n    \"pid\": 3447512,\n    \"hostname\": \"rinc1080ti-PR4764GW\",\n    \"node_ip\": \"114.212.87.168\",\n    \"config\": {\n      \"generic\": {\n        \"lr\": 0.001,\n        \"lradj\": \"step15\",\n        \"batch_size\": 32,\n        \"weight_decay\": 0\n      },\n      \"model\": {\n        \"feature_dim\": 128,\n        \"n_layers\": 4,\n        \"dropout\": 0\n      },\n      \"agent\": {}\n    },\n    \"time_since_restore\": 244.96328997612,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"warmup_time\": 0.0057446956634521484,\n    \"experiment_tag\": \"2_lradj=step15\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1714981488.9192555,\n  \"metric_analysis\": {\n    \"end_avg_acc\": {\n      \"max\": 80.18166666666667,\n      \"min\": 80.18166666666667,\n      \"avg\": 80.18166666666667,\n      \"last\": 80.18166666666667,\n      \"last-5-avg\": 80.18166666666667,\n      \"last-10-avg\": 80.18166666666667\n    },\n    \"end_avg_fgt\": {\n      \"max\": 25.97,\n      \"min\": 25.97,\n      \"avg\": 25.97,\n      \"last\": 25.97,\n      \"last-5-avg\": 25.97,\n      \"last-10-avg\": 25.97\n    },\n    \"avg_cur_acc\": {\n      \"max\": 97.495,\n      \"min\": 97.495,\n      \"avg\": 97.495,\n      \"last\": 97.495,\n      \"last-5-avg\": 97.495,\n      \"last-10-avg\": 97.495\n    },\n    \"time_this_iter_s\": {\n      \"max\": 244.96328997612,\n      \"min\": 244.96328997612,\n      \"avg\": 244.96328997612,\n      \"last\": 244.96328997612,\n      \"last-5-avg\": 244.96328997612,\n      \"last-10-avg\": 244.96328997612\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 244.96328997612,\n      \"min\": 244.96328997612,\n      \"avg\": 244.96328997612,\n      \"last\": 244.96328997612,\n      \"last-5-avg\": 244.96328997612,\n      \"last-10-avg\": 244.96328997612\n    },\n    \"time_since_restore\": {\n      \"max\": 244.96328997612,\n      \"min\": 244.96328997612,\n      \"avg\": 244.96328997612,\n      \"last\": 244.96328997612,\n      \"last-5-avg\": 244.96328997612,\n      \"last-10-avg\": 244.96328997612\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"warmup_time\": {\n      \"max\": 0.0057446956634521484,\n      \"min\": 0.0057446956634521484,\n      \"avg\": 0.0057446956634521484,\n      \"last\": 0.0057446956634521484,\n      \"last-5-avg\": 0.0057446956634521484,\n      \"last-10-avg\": 0.0057446956634521484\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"end_avg_acc\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308d4063a6da00b54409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308d4063a6da00b54409486945294612e\"\n      }\n    },\n    \"end_avg_fgt\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308b81e85eb51f839409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308b81e85eb51f839409486945294612e\"\n      }\n    },\n    \"avg_cur_acc\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430848e17a14ae5f58409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430848e17a14ae5f58409486945294612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447406e9ed345800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447406e9ed345800000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447406e9ed345800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447406e9ed345800000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447406e9ed345800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447406e9ed345800000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473f7787c000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473f7787c000000000612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1714981243.9400659,\n  \"relative_logdir\": \"c9af6_00002_2_lradj=step15_2024-05-06_15-40-43\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"trial_name_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059571020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b014b5343087c006a009b005300944e85948c08747269616c5f69649485948c01749485948c312f6469736b322f6c696875616a69616e2f545343494c2f6578706572696d656e742f74756e655f616e645f6578702e7079948c083c6c616d6264613e944ba543020800942929749452947d94288c0b5f5f7061636b6167655f5f948c0a6578706572696d656e74948c085f5f6e616d655f5f948c176578706572696d656e742e74756e655f616e645f657870948c085f5f66696c655f5f948c312f6469736b322f6c696875616a69616e2f545343494c2f6578706572696d656e742f74756e655f616e645f6578702e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681b7d947d94286816680f8c0c5f5f7175616c6e616d655f5f948c2f74756e655f6879706572706172616d735f6f6e5f76616c5f7461736b732e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": \"c9af6_00002\",\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"CNN_BN_ER\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c1273796e635f6f6e5f636865636b706f696e74948875622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bb020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f64617461944e8c026964944e8c0c73746f726167655f6d6f646594681b8c11436865636b706f696e7453746f726167659493944b01859452948c176c6f63616c5f746f5f72656d6f74655f706174685f666e944e8c076d657472696373947d948c076e6f64655f6970944e8c155f6d6f76655f696e73746561645f6f665f636f70799488756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_cl_agent_on_val_tasks\",\n  \"trial_id\": \"c9af6_00001\",\n  \"config\": {\n    \"generic\": {\n      \"lr\": 0.001,\n      \"lradj\": \"step10\",\n      \"batch_size\": 32,\n      \"weight_decay\": 0\n    },\n    \"model\": {\n      \"feature_dim\": 128,\n      \"n_layers\": 4,\n      \"dropout\": 0\n    },\n    \"agent\": {}\n  },\n  \"_local_dir\": \"/disk2/lihuajian/TSCIL/result/ray_tune_results/class/har/CNN_BN_ER\",\n  \"evaluated_params\": {\n    \"generic/lradj\": \"step10\"\n  },\n  \"experiment_tag\": \"1_lradj=step10\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740100000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"end_avg_acc\": 81.62666666666667,\n    \"end_avg_fgt\": 7.387499999999999,\n    \"avg_cur_acc\": 86.55166666666666,\n    \"Acc_across_runs\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059507010000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d627566666572949394289690000000000000000000000000005940000000000000000000000000000000001f85eb51b83e574000000000000059400000000000000000ec51b81e85ab5840e17a14ae47d154406666666666e64e400000000000005940000000000000000000000000000000008fc2f5285c1f584000000000000059400000000000000000ec51b81e85ab584014ae47e17a745640e17a14ae47c14c40948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b024b034b0387948c014394749452942e\"\n    },\n    \"time_this_iter_s\": 369.5502288341522,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"c9af6_00001\",\n    \"experiment_id\": \"a456c96e0feb4f67b5876a0f260d5776\",\n    \"date\": \"2024-05-06_15-40-43\",\n    \"timestamp\": 1714981243,\n    \"time_total_s\": 369.5502288341522,\n    \"pid\": 3447512,\n    \"hostname\": \"rinc1080ti-PR4764GW\",\n    \"node_ip\": \"114.212.87.168\",\n    \"config\": {\n      \"generic\": {\n        \"lr\": 0.001,\n        \"lradj\": \"step10\",\n        \"batch_size\": 32,\n        \"weight_decay\": 0\n      },\n      \"model\": {\n        \"feature_dim\": 128,\n        \"n_layers\": 4,\n        \"dropout\": 0\n      },\n      \"agent\": {}\n    },\n    \"time_since_restore\": 369.5502288341522,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"warmup_time\": 0.0057446956634521484,\n    \"experiment_tag\": \"1_lradj=step10\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1714981243.9025311,\n  \"metric_analysis\": {\n    \"end_avg_acc\": {\n      \"max\": 81.62666666666667,\n      \"min\": 81.62666666666667,\n      \"avg\": 81.62666666666667,\n      \"last\": 81.62666666666667,\n      \"last-5-avg\": 81.62666666666667,\n      \"last-10-avg\": 81.62666666666667\n    },\n    \"end_avg_fgt\": {\n      \"max\": 7.387499999999999,\n      \"min\": 7.387499999999999,\n      \"avg\": 7.387499999999999,\n      \"last\": 7.387499999999999,\n      \"last-5-avg\": 7.387499999999999,\n      \"last-10-avg\": 7.387499999999999\n    },\n    \"avg_cur_acc\": {\n      \"max\": 86.55166666666666,\n      \"min\": 86.55166666666666,\n      \"avg\": 86.55166666666666,\n      \"last\": 86.55166666666666,\n      \"last-5-avg\": 86.55166666666666,\n      \"last-10-avg\": 86.55166666666666\n    },\n    \"time_this_iter_s\": {\n      \"max\": 369.5502288341522,\n      \"min\": 369.5502288341522,\n      \"avg\": 369.5502288341522,\n      \"last\": 369.5502288341522,\n      \"last-5-avg\": 369.5502288341522,\n      \"last-10-avg\": 369.5502288341522\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 369.5502288341522,\n      \"min\": 369.5502288341522,\n      \"avg\": 369.5502288341522,\n      \"last\": 369.5502288341522,\n      \"last-5-avg\": 369.5502288341522,\n      \"last-10-avg\": 369.5502288341522\n    },\n    \"time_since_restore\": {\n      \"max\": 369.5502288341522,\n      \"min\": 369.5502288341522,\n      \"avg\": 369.5502288341522,\n      \"last\": 369.5502288341522,\n      \"last-5-avg\": 369.5502288341522,\n      \"last-10-avg\": 369.5502288341522\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"warmup_time\": {\n      \"max\": 0.0057446956634521484,\n      \"min\": 0.0057446956634521484,\n      \"avg\": 0.0057446956634521484,\n      \"last\": 0.0057446956634521484,\n      \"last-5-avg\": 0.0057446956634521484,\n      \"last-10-avg\": 0.0057446956634521484\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"end_avg_acc\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308e8b4814e1b6854409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308e8b4814e1b6854409486945294612e\"\n      }\n    },\n    \"end_avg_fgt\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cccccccccc8c1d409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cccccccccc8c1d409486945294612e\"\n      }\n    },\n    \"avg_cur_acc\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243081be8b4814ea355409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243081be8b4814ea355409486945294612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447407718cdbcc00000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447407718cdbcc00000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447407718cdbcc00000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447407718cdbcc00000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447407718cdbcc00000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447407718cdbcc00000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473f7787c000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473f7787c000000000612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1714980874.3360617,\n  \"relative_logdir\": \"c9af6_00001_1_lradj=step10_2024-05-06_15-34-34\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"trial_name_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059571020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b014b5343087c006a009b005300944e85948c08747269616c5f69649485948c01749485948c312f6469736b322f6c696875616a69616e2f545343494c2f6578706572696d656e742f74756e655f616e645f6578702e7079948c083c6c616d6264613e944ba543020800942929749452947d94288c0b5f5f7061636b6167655f5f948c0a6578706572696d656e74948c085f5f6e616d655f5f948c176578706572696d656e742e74756e655f616e645f657870948c085f5f66696c655f5f948c312f6469736b322f6c696875616a69616e2f545343494c2f6578706572696d656e742f74756e655f616e645f6578702e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681b7d947d94286816680f8c0c5f5f7175616c6e616d655f5f948c2f74756e655f6879706572706172616d735f6f6e5f76616c5f7461736b732e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": \"c9af6_00001\",\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"CNN_BN_ER\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c1273796e635f6f6e5f636865636b706f696e74948875622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bb020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f64617461944e8c026964944e8c0c73746f726167655f6d6f646594681b8c11436865636b706f696e7453746f726167659493944b01859452948c176c6f63616c5f746f5f72656d6f74655f706174685f666e944e8c076d657472696373947d948c076e6f64655f6970944e8c155f6d6f76655f696e73746561645f6f665f636f70799488756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_cl_agent_on_val_tasks\",\n  \"trial_id\": \"c9af6_00000\",\n  \"config\": {\n    \"generic\": {\n      \"lr\": 0.001,\n      \"lradj\": \"TST\",\n      \"batch_size\": 32,\n      \"weight_decay\": 0\n    },\n    \"model\": {\n      \"feature_dim\": 128,\n      \"n_layers\": 4,\n      \"dropout\": 0\n    },\n    \"agent\": {}\n  },\n  \"_local_dir\": \"/disk2/lihuajian/TSCIL/result/ray_tune_results/class/har/CNN_BN_ER\",\n  \"evaluated_params\": {\n    \"generic/lradj\": \"TST\"\n  },\n  \"experiment_tag\": \"0_lradj=TST\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740100000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"end_avg_acc\": 80.79666666666665,\n    \"end_avg_fgt\": 11.530000000000001,\n    \"avg_cur_acc\": 88.48333333333332,\n    \"Acc_across_runs\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059507010000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d627566666572949394289690000000000000000000000000005940000000000000000000000000000000007b14ae47e1ea56400000000000005940000000000000000000000000009058403333333333a35540cdcccccccc6c56400000000000005940000000000000000000000000000000000ad7a3703d7a564000000000000059400000000000000000a4703d0ad7735840e17a14ae47d151409a99999999994440948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b024b034b0387948c014394749452942e\"\n    },\n    \"time_this_iter_s\": 552.3473813533783,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"c9af6_00000\",\n    \"experiment_id\": \"a456c96e0feb4f67b5876a0f260d5776\",\n    \"date\": \"2024-05-06_15-34-34\",\n    \"timestamp\": 1714980874,\n    \"time_total_s\": 552.3473813533783,\n    \"pid\": 3447512,\n    \"hostname\": \"rinc1080ti-PR4764GW\",\n    \"node_ip\": \"114.212.87.168\",\n    \"config\": {\n      \"generic\": {\n        \"lr\": 0.001,\n        \"lradj\": \"TST\",\n        \"batch_size\": 32,\n        \"weight_decay\": 0\n      },\n      \"model\": {\n        \"feature_dim\": 128,\n        \"n_layers\": 4,\n        \"dropout\": 0\n      },\n      \"agent\": {}\n    },\n    \"time_since_restore\": 552.3473813533783,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"warmup_time\": 0.0057446956634521484,\n    \"experiment_tag\": \"0_lradj=TST\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1714980874.1803508,\n  \"metric_analysis\": {\n    \"end_avg_acc\": {\n      \"max\": 80.79666666666665,\n      \"min\": 80.79666666666665,\n      \"avg\": 80.79666666666665,\n      \"last\": 80.79666666666665,\n      \"last-5-avg\": 80.79666666666665,\n      \"last-10-avg\": 80.79666666666665\n    },\n    \"end_avg_fgt\": {\n      \"max\": 11.530000000000001,\n      \"min\": 11.530000000000001,\n      \"avg\": 11.530000000000001,\n      \"last\": 11.530000000000001,\n      \"last-5-avg\": 11.530000000000001,\n      \"last-10-avg\": 11.530000000000001\n    },\n    \"avg_cur_acc\": {\n      \"max\": 88.48333333333332,\n      \"min\": 88.48333333333332,\n      \"avg\": 88.48333333333332,\n      \"last\": 88.48333333333332,\n      \"last-5-avg\": 88.48333333333332,\n      \"last-10-avg\": 88.48333333333332\n    },\n    \"time_this_iter_s\": {\n      \"max\": 552.3473813533783,\n      \"min\": 552.3473813533783,\n      \"avg\": 552.3473813533783,\n      \"last\": 552.3473813533783,\n      \"last-5-avg\": 552.3473813533783,\n      \"last-10-avg\": 552.3473813533783\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 552.3473813533783,\n      \"min\": 552.3473813533783,\n      \"avg\": 552.3473813533783,\n      \"last\": 552.3473813533783,\n      \"last-5-avg\": 552.3473813533783,\n      \"last-10-avg\": 552.3473813533783\n    },\n    \"time_since_restore\": {\n      \"max\": 552.3473813533783,\n      \"min\": 552.3473813533783,\n      \"avg\": 552.3473813533783,\n      \"last\": 552.3473813533783,\n      \"last-5-avg\": 552.3473813533783,\n      \"last-10-avg\": 552.3473813533783\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"warmup_time\": {\n      \"max\": 0.0057446956634521484,\n      \"min\": 0.0057446956634521484,\n      \"avg\": 0.0057446956634521484,\n      \"last\": 0.0057446956634521484,\n      \"last-5-avg\": 0.0057446956634521484,\n      \"last-10-avg\": 0.0057446956634521484\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"end_avg_acc\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430862c92f96fc3254409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430862c92f96fc3254409486945294612e\"\n      }\n    },\n    \"end_avg_fgt\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430890c2f5285c0f27409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430890c2f5285c0f27409486945294612e\"\n      }\n    },\n    \"avg_cur_acc\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308eeeeeeeeee1e56409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308eeeeeeeeee1e56409486945294612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447408142c76fe00000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447408142c76fe00000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447408142c76fe00000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447408142c76fe00000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447408142c76fe00000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447408142c76fe00000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473f7787c000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473f7787c000000000612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1714980317.5155492,\n  \"relative_logdir\": \"c9af6_00000_0_lradj=TST_2024-05-06_15-25-17\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"trial_name_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059571020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b014b5343087c006a009b005300944e85948c08747269616c5f69649485948c01749485948c312f6469736b322f6c696875616a69616e2f545343494c2f6578706572696d656e742f74756e655f616e645f6578702e7079948c083c6c616d6264613e944ba543020800942929749452947d94288c0b5f5f7061636b6167655f5f948c0a6578706572696d656e74948c085f5f6e616d655f5f948c176578706572696d656e742e74756e655f616e645f657870948c085f5f66696c655f5f948c312f6469736b322f6c696875616a69616e2f545343494c2f6578706572696d656e742f74756e655f616e645f6578702e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681b7d947d94286816680f8c0c5f5f7175616c6e616d655f5f948c2f74756e655f6879706572706172616d735f6f6e5f76616c5f7461736b732e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": \"c9af6_00000\",\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"CNN_BN_ER\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c1273796e635f6f6e5f636865636b706f696e74948875622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bb020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f64617461944e8c026964944e8c0c73746f726167655f6d6f646594681b8c11436865636b706f696e7453746f726167659493944b01859452948c176c6f63616c5f746f5f72656d6f74655f706174685f666e944e8c076d657472696373947d948c076e6f64655f6970944e8c155f6d6f76655f696e73746561645f6f665f636f70799488756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}"
  ],
  "runner_data": {
    "_insufficient_resources_manager": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "80059596000000000000008c317261792e74756e652e657865637574696f6e2e696e73756666696369656e745f7265736f75726365735f6d616e61676572948c1d5f496e73756666696369656e745265736f75726365734d616e616765729493942981947d94288c185f6e6f5f72756e6e696e675f747269616c735f73696e6365944affffffff8c0f5f6c6173745f747269616c5f6e756d944affffffff75622e"
    },
    "_max_pending_trials": 35,
    "_metric": null,
    "_total_time": 2333.721800327301,
    "_iteration": 241,
    "_has_errored": false,
    "_fail_fast": false,
    "_print_trial_errors": true,
    "_server_port": null,
    "_cached_trial_decisions": {},
    "_queued_trial_decisions": {},
    "_should_stop_experiment": false,
    "_stopper": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "8005952c000000000000008c157261792e74756e652e73746f707065722e6e6f6f70948c0b4e6f6f7053746f707065729493942981942e"
    },
    "_resumed": false,
    "_start_time": 1714980317.4477363,
    "_last_checkpoint_time": -Infinity,
    "_session_str": "2024-05-06_15-25-17",
    "checkpoint_file": "/disk2/lihuajian/TSCIL/result/ray_tune_results/class/har/CNN_BN_ER/experiment_state-2024-05-06_15-25-17.json",
    "_checkpoint_period": "auto",
    "_trial_checkpoint_config": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "800595ab000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c00948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e"
    },
    "launch_web_server": false
  },
  "stats": {
    "start_time": 1714980317.4477363,
    "timestamp": 1714981484.1033208
  }
}