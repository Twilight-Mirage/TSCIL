{
  "checkpoints": [
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_cl_agent_on_val_tasks\",\n  \"trial_id\": \"4bcd6_00000\",\n  \"config\": {\n    \"generic\": {\n      \"lr\": 0.001,\n      \"lradj\": \"TST\",\n      \"batch_size\": 32,\n      \"weight_decay\": 0\n    },\n    \"model\": {\n      \"feature_dim\": 128,\n      \"n_layers\": 4,\n      \"dropout\": 0\n    },\n    \"agent\": {}\n  },\n  \"_local_dir\": \"/disk2/lihuajian/TSCIL/result/ray_tune_results/class/har/CNN_BN_ER\",\n  \"evaluated_params\": {\n    \"generic/lradj\": \"TST\"\n  },\n  \"experiment_tag\": \"0_lradj=TST\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740100000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"end_avg_acc\": 82.525,\n    \"end_avg_fgt\": 14.7275,\n    \"avg_cur_acc\": 91.55666666666667,\n    \"Acc_across_runs\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059507010000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d6275666665729493942896900000000000000000000000000059400000000000000000000000000000000000000000000059407b14ae47e14a5840000000000000000014ae47e17a744940a4703d0ad7c35840f6285c8fc26558400000000000005940000000000000000000000000000000000000000000005940f6285c8fc29557400000000000000000ec51b81e858b56407b14ae47e14a58401f85eb51b81e4e40948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b024b034b0387948c014394749452942e\"\n    },\n    \"time_this_iter_s\": 315.4398114681244,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"4bcd6_00000\",\n    \"experiment_id\": \"7f0e534c3b6f443f9290583796680336\",\n    \"date\": \"2024-05-06_16-10-03\",\n    \"timestamp\": 1714983003,\n    \"time_total_s\": 315.4398114681244,\n    \"pid\": 3587892,\n    \"hostname\": \"rinc1080ti-PR4764GW\",\n    \"node_ip\": \"114.212.87.168\",\n    \"config\": {\n      \"generic\": {\n        \"lr\": 0.001,\n        \"lradj\": \"TST\",\n        \"batch_size\": 32,\n        \"weight_decay\": 0\n      },\n      \"model\": {\n        \"feature_dim\": 128,\n        \"n_layers\": 4,\n        \"dropout\": 0\n      },\n      \"agent\": {}\n    },\n    \"time_since_restore\": 315.4398114681244,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"warmup_time\": 0.005360841751098633,\n    \"experiment_tag\": \"0_lradj=TST\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1714983003.3259954,\n  \"metric_analysis\": {\n    \"end_avg_acc\": {\n      \"max\": 82.525,\n      \"min\": 82.525,\n      \"avg\": 82.525,\n      \"last\": 82.525,\n      \"last-5-avg\": 82.525,\n      \"last-10-avg\": 82.525\n    },\n    \"end_avg_fgt\": {\n      \"max\": 14.7275,\n      \"min\": 14.7275,\n      \"avg\": 14.7275,\n      \"last\": 14.7275,\n      \"last-5-avg\": 14.7275,\n      \"last-10-avg\": 14.7275\n    },\n    \"avg_cur_acc\": {\n      \"max\": 91.55666666666667,\n      \"min\": 91.55666666666667,\n      \"avg\": 91.55666666666667,\n      \"last\": 91.55666666666667,\n      \"last-5-avg\": 91.55666666666667,\n      \"last-10-avg\": 91.55666666666667\n    },\n    \"time_this_iter_s\": {\n      \"max\": 315.4398114681244,\n      \"min\": 315.4398114681244,\n      \"avg\": 315.4398114681244,\n      \"last\": 315.4398114681244,\n      \"last-5-avg\": 315.4398114681244,\n      \"last-10-avg\": 315.4398114681244\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 315.4398114681244,\n      \"min\": 315.4398114681244,\n      \"avg\": 315.4398114681244,\n      \"last\": 315.4398114681244,\n      \"last-5-avg\": 315.4398114681244,\n      \"last-10-avg\": 315.4398114681244\n    },\n    \"time_since_restore\": {\n      \"max\": 315.4398114681244,\n      \"min\": 315.4398114681244,\n      \"avg\": 315.4398114681244,\n      \"last\": 315.4398114681244,\n      \"last-5-avg\": 315.4398114681244,\n      \"last-10-avg\": 315.4398114681244\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"warmup_time\": {\n      \"max\": 0.005360841751098633,\n      \"min\": 0.005360841751098633,\n      \"avg\": 0.005360841751098633,\n      \"last\": 0.005360841751098633,\n      \"last-5-avg\": 0.005360841751098633,\n      \"last-10-avg\": 0.005360841751098633\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"end_avg_acc\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a99999999a154409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a99999999a154409486945294612e\"\n      }\n    },\n    \"end_avg_fgt\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430814ae47e17a742d409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430814ae47e17a742d409486945294612e\"\n      }\n    },\n    \"avg_cur_acc\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308d4063a6da0e356409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308d4063a6da0e356409486945294612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474073b70977c00000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474073b70977c00000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474073b70977c00000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474073b70977c00000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474073b70977c00000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474073b70977c00000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473f75f54000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473f75f54000000000612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1714982683.6977086,\n  \"relative_logdir\": \"4bcd6_00000_0_lradj=TST_2024-05-06_16-04-43\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"trial_name_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059571020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b014b5343087c006a009b005300944e85948c08747269616c5f69649485948c01749485948c312f6469736b322f6c696875616a69616e2f545343494c2f6578706572696d656e742f74756e655f616e645f6578702e7079948c083c6c616d6264613e944ba543020800942929749452947d94288c0b5f5f7061636b6167655f5f948c0a6578706572696d656e74948c085f5f6e616d655f5f948c176578706572696d656e742e74756e655f616e645f657870948c085f5f66696c655f5f948c312f6469736b322f6c696875616a69616e2f545343494c2f6578706572696d656e742f74756e655f616e645f6578702e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681b7d947d94286816680f8c0c5f5f7175616c6e616d655f5f948c2f74756e655f6879706572706172616d735f6f6e5f76616c5f7461736b732e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": \"4bcd6_00000\",\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"CNN_BN_ER\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c1273796e635f6f6e5f636865636b706f696e74948875622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bb020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f64617461944e8c026964944e8c0c73746f726167655f6d6f646594681b8c11436865636b706f696e7453746f726167659493944b01859452948c176c6f63616c5f746f5f72656d6f74655f706174685f666e944e8c076d657472696373947d948c076e6f64655f6970944e8c155f6d6f76655f696e73746561645f6f665f636f70799488756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_cl_agent_on_val_tasks\",\n  \"trial_id\": \"4bcd6_00002\",\n  \"config\": {\n    \"generic\": {\n      \"lr\": 0.001,\n      \"lradj\": \"step15\",\n      \"batch_size\": 32,\n      \"weight_decay\": 0\n    },\n    \"model\": {\n      \"feature_dim\": 128,\n      \"n_layers\": 4,\n      \"dropout\": 0\n    },\n    \"agent\": {}\n  },\n  \"_local_dir\": \"/disk2/lihuajian/TSCIL/result/ray_tune_results/class/har/CNN_BN_ER\",\n  \"evaluated_params\": {\n    \"generic/lradj\": \"step15\"\n  },\n  \"experiment_tag\": \"2_lradj=step15\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740100000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"end_avg_acc\": 74.51833333333335,\n    \"end_avg_fgt\": 27.814999999999998,\n    \"avg_cur_acc\": 93.06166666666667,\n    \"Acc_across_runs\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059507010000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d627566666572949394289690000000000000000000000000005940000000000000000000000000000000000000000000005940a4703d0ad7c3584000000000000000003d0ad7a3705d48401f85eb51b80e58409a99999999b94e400000000000005940000000000000000000000000000000003333333333a35840a4703d0ad7c3584000000000000000009a99999999b94840cdcccccccc1c57403333333333b35840948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b024b034b0387948c014394749452942e\"\n    },\n    \"time_this_iter_s\": 225.14283323287964,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"4bcd6_00002\",\n    \"experiment_id\": \"7f0e534c3b6f443f9290583796680336\",\n    \"date\": \"2024-05-06_16-20-22\",\n    \"timestamp\": 1714983622,\n    \"time_total_s\": 225.14283323287964,\n    \"pid\": 3587892,\n    \"hostname\": \"rinc1080ti-PR4764GW\",\n    \"node_ip\": \"114.212.87.168\",\n    \"config\": {\n      \"generic\": {\n        \"lr\": 0.001,\n        \"lradj\": \"step15\",\n        \"batch_size\": 32,\n        \"weight_decay\": 0\n      },\n      \"model\": {\n        \"feature_dim\": 128,\n        \"n_layers\": 4,\n        \"dropout\": 0\n      },\n      \"agent\": {}\n    },\n    \"time_since_restore\": 225.14283323287964,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"warmup_time\": 0.005360841751098633,\n    \"experiment_tag\": \"2_lradj=step15\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1714983622.3189728,\n  \"metric_analysis\": {\n    \"end_avg_acc\": {\n      \"max\": 74.51833333333335,\n      \"min\": 74.51833333333335,\n      \"avg\": 74.51833333333335,\n      \"last\": 74.51833333333335,\n      \"last-5-avg\": 74.51833333333335,\n      \"last-10-avg\": 74.51833333333335\n    },\n    \"end_avg_fgt\": {\n      \"max\": 27.814999999999998,\n      \"min\": 27.814999999999998,\n      \"avg\": 27.814999999999998,\n      \"last\": 27.814999999999998,\n      \"last-5-avg\": 27.814999999999998,\n      \"last-10-avg\": 27.814999999999998\n    },\n    \"avg_cur_acc\": {\n      \"max\": 93.06166666666667,\n      \"min\": 93.06166666666667,\n      \"avg\": 93.06166666666667,\n      \"last\": 93.06166666666667,\n      \"last-5-avg\": 93.06166666666667,\n      \"last-10-avg\": 93.06166666666667\n    },\n    \"time_this_iter_s\": {\n      \"max\": 225.14283323287964,\n      \"min\": 225.14283323287964,\n      \"avg\": 225.14283323287964,\n      \"last\": 225.14283323287964,\n      \"last-5-avg\": 225.14283323287964,\n      \"last-10-avg\": 225.14283323287964\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 225.14283323287964,\n      \"min\": 225.14283323287964,\n      \"avg\": 225.14283323287964,\n      \"last\": 225.14283323287964,\n      \"last-5-avg\": 225.14283323287964,\n      \"last-10-avg\": 225.14283323287964\n    },\n    \"time_since_restore\": {\n      \"max\": 225.14283323287964,\n      \"min\": 225.14283323287964,\n      \"avg\": 225.14283323287964,\n      \"last\": 225.14283323287964,\n      \"last-5-avg\": 225.14283323287964,\n      \"last-10-avg\": 225.14283323287964\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"warmup_time\": {\n      \"max\": 0.005360841751098633,\n      \"min\": 0.005360841751098633,\n      \"avg\": 0.005360841751098633,\n      \"last\": 0.005360841751098633,\n      \"last-5-avg\": 0.005360841751098633,\n      \"last-10-avg\": 0.005360841751098633\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"end_avg_acc\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308fac5925f2ca152409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308fac5925f2ca152409486945294612e\"\n      }\n    },\n    \"end_avg_fgt\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308703d0ad7a3d03b409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308703d0ad7a3d03b409486945294612e\"\n      }\n    },\n    \"avg_cur_acc\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243088c25bf58f24357409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243088c25bf58f24357409486945294612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447406c249217000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447406c249217000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447406c249217000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447406c249217000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447406c249217000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447406c249217000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473f75f54000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473f75f54000000000612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1714983397.1589038,\n  \"relative_logdir\": \"4bcd6_00002_2_lradj=step15_2024-05-06_16-16-37\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"trial_name_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059571020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b014b5343087c006a009b005300944e85948c08747269616c5f69649485948c01749485948c312f6469736b322f6c696875616a69616e2f545343494c2f6578706572696d656e742f74756e655f616e645f6578702e7079948c083c6c616d6264613e944ba543020800942929749452947d94288c0b5f5f7061636b6167655f5f948c0a6578706572696d656e74948c085f5f6e616d655f5f948c176578706572696d656e742e74756e655f616e645f657870948c085f5f66696c655f5f948c312f6469736b322f6c696875616a69616e2f545343494c2f6578706572696d656e742f74756e655f616e645f6578702e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681b7d947d94286816680f8c0c5f5f7175616c6e616d655f5f948c2f74756e655f6879706572706172616d735f6f6e5f76616c5f7461736b732e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": \"4bcd6_00002\",\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"CNN_BN_ER\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c1273796e635f6f6e5f636865636b706f696e74948875622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bb020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f64617461944e8c026964944e8c0c73746f726167655f6d6f646594681b8c11436865636b706f696e7453746f726167659493944b01859452948c176c6f63616c5f746f5f72656d6f74655f706174685f666e944e8c076d657472696373947d948c076e6f64655f6970944e8c155f6d6f76655f696e73746561645f6f665f636f70799488756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_cl_agent_on_val_tasks\",\n  \"trial_id\": \"4bcd6_00001\",\n  \"config\": {\n    \"generic\": {\n      \"lr\": 0.001,\n      \"lradj\": \"step10\",\n      \"batch_size\": 32,\n      \"weight_decay\": 0\n    },\n    \"model\": {\n      \"feature_dim\": 128,\n      \"n_layers\": 4,\n      \"dropout\": 0\n    },\n    \"agent\": {}\n  },\n  \"_local_dir\": \"/disk2/lihuajian/TSCIL/result/ray_tune_results/class/har/CNN_BN_ER\",\n  \"evaluated_params\": {\n    \"generic/lradj\": \"step10\"\n  },\n  \"experiment_tag\": \"1_lradj=step10\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740100000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"end_avg_acc\": 73.24,\n    \"end_avg_fgt\": 38.53,\n    \"avg_cur_acc\": 98.92666666666668,\n    \"Acc_across_runs\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059507010000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d62756666657294939428969000000000000000000000000000594000000000000000000000000000000000000000000000594052b81e85ebe158400000000000000000a4703d0ad7a31b40a4703d0ad7b357403333333333b358400000000000005940000000000000000000000000000000000000000000005940295c8fc2f56858400000000000000000295c8fc2f5e84840713d0ad7a3e05640f6285c8fc2655840948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b024b034b0387948c014394749452942e\"\n    },\n    \"time_this_iter_s\": 393.6083445549011,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"4bcd6_00001\",\n    \"experiment_id\": \"7f0e534c3b6f443f9290583796680336\",\n    \"date\": \"2024-05-06_16-16-37\",\n    \"timestamp\": 1714983397,\n    \"time_total_s\": 393.6083445549011,\n    \"pid\": 3587892,\n    \"hostname\": \"rinc1080ti-PR4764GW\",\n    \"node_ip\": \"114.212.87.168\",\n    \"config\": {\n      \"generic\": {\n        \"lr\": 0.001,\n        \"lradj\": \"step10\",\n        \"batch_size\": 32,\n        \"weight_decay\": 0\n      },\n      \"model\": {\n        \"feature_dim\": 128,\n        \"n_layers\": 4,\n        \"dropout\": 0\n      },\n      \"agent\": {}\n    },\n    \"time_since_restore\": 393.6083445549011,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"warmup_time\": 0.005360841751098633,\n    \"experiment_tag\": \"1_lradj=step10\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1714983397.1157608,\n  \"metric_analysis\": {\n    \"end_avg_acc\": {\n      \"max\": 73.24,\n      \"min\": 73.24,\n      \"avg\": 73.24,\n      \"last\": 73.24,\n      \"last-5-avg\": 73.24,\n      \"last-10-avg\": 73.24\n    },\n    \"end_avg_fgt\": {\n      \"max\": 38.53,\n      \"min\": 38.53,\n      \"avg\": 38.53,\n      \"last\": 38.53,\n      \"last-5-avg\": 38.53,\n      \"last-10-avg\": 38.53\n    },\n    \"avg_cur_acc\": {\n      \"max\": 98.92666666666668,\n      \"min\": 98.92666666666668,\n      \"avg\": 98.92666666666668,\n      \"last\": 98.92666666666668,\n      \"last-5-avg\": 98.92666666666668,\n      \"last-10-avg\": 98.92666666666668\n    },\n    \"time_this_iter_s\": {\n      \"max\": 393.6083445549011,\n      \"min\": 393.6083445549011,\n      \"avg\": 393.6083445549011,\n      \"last\": 393.6083445549011,\n      \"last-5-avg\": 393.6083445549011,\n      \"last-10-avg\": 393.6083445549011\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 393.6083445549011,\n      \"min\": 393.6083445549011,\n      \"avg\": 393.6083445549011,\n      \"last\": 393.6083445549011,\n      \"last-5-avg\": 393.6083445549011,\n      \"last-10-avg\": 393.6083445549011\n    },\n    \"time_since_restore\": {\n      \"max\": 393.6083445549011,\n      \"min\": 393.6083445549011,\n      \"avg\": 393.6083445549011,\n      \"last\": 393.6083445549011,\n      \"last-5-avg\": 393.6083445549011,\n      \"last-10-avg\": 393.6083445549011\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"warmup_time\": {\n      \"max\": 0.005360841751098633,\n      \"min\": 0.005360841751098633,\n      \"avg\": 0.005360841751098633,\n      \"last\": 0.005360841751098633,\n      \"last-5-avg\": 0.005360841751098633,\n      \"last-10-avg\": 0.005360841751098633\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"end_avg_acc\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243088fc2f5285c4f52409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243088fc2f5285c4f52409486945294612e\"\n      }\n    },\n    \"end_avg_fgt\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308a4703d0ad74343409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308a4703d0ad74343409486945294612e\"\n      }\n    },\n    \"avg_cur_acc\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243081ce8b4814ebb58409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243081ce8b4814ebb58409486945294612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447407899bbc7800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447407899bbc7800000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447407899bbc7800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447407899bbc7800000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447407899bbc7800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447407899bbc7800000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473f75f54000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473f75f54000000000612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1714983003.4915845,\n  \"relative_logdir\": \"4bcd6_00001_1_lradj=step10_2024-05-06_16-10-03\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"trial_name_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059571020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b014b5343087c006a009b005300944e85948c08747269616c5f69649485948c01749485948c312f6469736b322f6c696875616a69616e2f545343494c2f6578706572696d656e742f74756e655f616e645f6578702e7079948c083c6c616d6264613e944ba543020800942929749452947d94288c0b5f5f7061636b6167655f5f948c0a6578706572696d656e74948c085f5f6e616d655f5f948c176578706572696d656e742e74756e655f616e645f657870948c085f5f66696c655f5f948c312f6469736b322f6c696875616a69616e2f545343494c2f6578706572696d656e742f74756e655f616e645f6578702e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681b7d947d94286816680f8c0c5f5f7175616c6e616d655f5f948c2f74756e655f6879706572706172616d735f6f6e5f76616c5f7461736b732e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": \"4bcd6_00001\",\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"CNN_BN_ER\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c1273796e635f6f6e5f636865636b706f696e74948875622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bb020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f64617461944e8c026964944e8c0c73746f726167655f6d6f646594681b8c11436865636b706f696e7453746f726167659493944b01859452948c176c6f63616c5f746f5f72656d6f74655f706174685f666e944e8c076d657472696373947d948c076e6f64655f6970944e8c155f6d6f76655f696e73746561645f6f665f636f70799488756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}"
  ],
  "runner_data": {
    "_insufficient_resources_manager": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "80059596000000000000008c317261792e74756e652e657865637574696f6e2e696e73756666696369656e745f7265736f75726365735f6d616e61676572948c1d5f496e73756666696369656e745265736f75726365734d616e616765729493942981947d94288c185f6e6f5f72756e6e696e675f747269616c735f73696e6365944affffffff8c0f5f6c6173745f747269616c5f6e756d944affffffff75622e"
    },
    "_max_pending_trials": 35,
    "_metric": null,
    "_total_time": 1868.3819785118103,
    "_iteration": 194,
    "_has_errored": false,
    "_fail_fast": false,
    "_print_trial_errors": true,
    "_server_port": null,
    "_cached_trial_decisions": {},
    "_queued_trial_decisions": {},
    "_should_stop_experiment": false,
    "_stopper": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "8005952c000000000000008c157261792e74756e652e73746f707065722e6e6f6f70948c0b4e6f6f7053746f707065729493942981942e"
    },
    "_resumed": false,
    "_start_time": 1714982683.2316513,
    "_last_checkpoint_time": -Infinity,
    "_session_str": "2024-05-06_16-04-43",
    "checkpoint_file": "/disk2/lihuajian/TSCIL/result/ray_tune_results/class/har/CNN_BN_ER/experiment_state-2024-05-06_16-04-43.json",
    "_checkpoint_period": "auto",
    "_trial_checkpoint_config": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "800595ab000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c00948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e"
    },
    "launch_web_server": false
  },
  "stats": {
    "start_time": 1714982683.2316513,
    "timestamp": 1714983622.3245444
  }
}