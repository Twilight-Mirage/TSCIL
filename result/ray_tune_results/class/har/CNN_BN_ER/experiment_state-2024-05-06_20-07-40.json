{
  "checkpoints": [
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_cl_agent_on_val_tasks\",\n  \"trial_id\": \"3c642_00002\",\n  \"config\": {\n    \"generic\": {\n      \"lr\": 0.001,\n      \"lradj\": \"step15\",\n      \"batch_size\": 32,\n      \"weight_decay\": 0\n    },\n    \"model\": {\n      \"feature_dim\": 128,\n      \"n_layers\": 4,\n      \"dropout\": 0\n    },\n    \"agent\": {}\n  },\n  \"_local_dir\": \"/disk2/lihuajian/TSCIL/result/ray_tune_results/class/har/CNN_BN_ER\",\n  \"evaluated_params\": {\n    \"generic/lradj\": \"step15\"\n  },\n  \"experiment_tag\": \"2_lradj=step15\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740100000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"end_avg_acc\": 64.855,\n    \"end_avg_fgt\": 24.582500000000003,\n    \"avg_cur_acc\": 81.24333333333334,\n    \"Acc_across_runs\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059507010000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d627566666572949394289690000000000000000000000000005940000000000000000000000000000000008fc2f5285c1f584048e17a14aed7564000000000000000001f85eb51b83e5740713d0ad7a3f02e403d0ad7a370bd4a40000000000000594000000000000000000000000000000000ae47e17a145e56400000000000005940000000000000000066666666669656408fc2f5285c8f5740ae47e17a144e4540948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b024b034b0387948c014394749452942e\"\n    },\n    \"time_this_iter_s\": 242.3454191684723,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"3c642_00002\",\n    \"experiment_id\": \"13853cebda1e42c99726250ec20db2f8\",\n    \"date\": \"2024-05-06_20-16-55\",\n    \"timestamp\": 1714997815,\n    \"time_total_s\": 242.3454191684723,\n    \"pid\": 3962548,\n    \"hostname\": \"rinc1080ti-PR4764GW\",\n    \"node_ip\": \"114.212.87.168\",\n    \"config\": {\n      \"generic\": {\n        \"lr\": 0.001,\n        \"lradj\": \"step15\",\n        \"batch_size\": 32,\n        \"weight_decay\": 0\n      },\n      \"model\": {\n        \"feature_dim\": 128,\n        \"n_layers\": 4,\n        \"dropout\": 0\n      },\n      \"agent\": {}\n    },\n    \"time_since_restore\": 242.3454191684723,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"warmup_time\": 0.005312204360961914,\n    \"experiment_tag\": \"2_lradj=step15\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1714997815.6002243,\n  \"metric_analysis\": {\n    \"end_avg_acc\": {\n      \"max\": 64.855,\n      \"min\": 64.855,\n      \"avg\": 64.855,\n      \"last\": 64.855,\n      \"last-5-avg\": 64.855,\n      \"last-10-avg\": 64.855\n    },\n    \"end_avg_fgt\": {\n      \"max\": 24.582500000000003,\n      \"min\": 24.582500000000003,\n      \"avg\": 24.582500000000003,\n      \"last\": 24.582500000000003,\n      \"last-5-avg\": 24.582500000000003,\n      \"last-10-avg\": 24.582500000000003\n    },\n    \"avg_cur_acc\": {\n      \"max\": 81.24333333333334,\n      \"min\": 81.24333333333334,\n      \"avg\": 81.24333333333334,\n      \"last\": 81.24333333333334,\n      \"last-5-avg\": 81.24333333333334,\n      \"last-10-avg\": 81.24333333333334\n    },\n    \"time_this_iter_s\": {\n      \"max\": 242.3454191684723,\n      \"min\": 242.3454191684723,\n      \"avg\": 242.3454191684723,\n      \"last\": 242.3454191684723,\n      \"last-5-avg\": 242.3454191684723,\n      \"last-10-avg\": 242.3454191684723\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 242.3454191684723,\n      \"min\": 242.3454191684723,\n      \"avg\": 242.3454191684723,\n      \"last\": 242.3454191684723,\n      \"last-5-avg\": 242.3454191684723,\n      \"last-10-avg\": 242.3454191684723\n    },\n    \"time_since_restore\": {\n      \"max\": 242.3454191684723,\n      \"min\": 242.3454191684723,\n      \"avg\": 242.3454191684723,\n      \"last\": 242.3454191684723,\n      \"last-5-avg\": 242.3454191684723,\n      \"last-10-avg\": 242.3454191684723\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"warmup_time\": {\n      \"max\": 0.005312204360961914,\n      \"min\": 0.005312204360961914,\n      \"avg\": 0.005312204360961914,\n      \"last\": 0.005312204360961914,\n      \"last-5-avg\": 0.005312204360961914,\n      \"last-10-avg\": 0.005312204360961914\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"end_avg_acc\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243081f85eb51b83650409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243081f85eb51b83650409486945294612e\"\n      }\n    },\n    \"end_avg_fgt\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430886eb51b81e9538409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430886eb51b81e9538409486945294612e\"\n      }\n    },\n    \"avg_cur_acc\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308602cf9c5924f54409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308602cf9c5924f54409486945294612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447406e4b0dac800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447406e4b0dac800000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447406e4b0dac800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447406e4b0dac800000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447406e4b0dac800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447406e4b0dac800000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473f75c24000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473f75c24000000000612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1714997573.241597,\n  \"relative_logdir\": \"3c642_00002_2_lradj=step15_2024-05-06_20-12-53\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"trial_name_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059571020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b014b5343087c006a009b005300944e85948c08747269616c5f69649485948c01749485948c312f6469736b322f6c696875616a69616e2f545343494c2f6578706572696d656e742f74756e655f616e645f6578702e7079948c083c6c616d6264613e944ba543020800942929749452947d94288c0b5f5f7061636b6167655f5f948c0a6578706572696d656e74948c085f5f6e616d655f5f948c176578706572696d656e742e74756e655f616e645f657870948c085f5f66696c655f5f948c312f6469736b322f6c696875616a69616e2f545343494c2f6578706572696d656e742f74756e655f616e645f6578702e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681b7d947d94286816680f8c0c5f5f7175616c6e616d655f5f948c2f74756e655f6879706572706172616d735f6f6e5f76616c5f7461736b732e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": \"3c642_00002\",\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"CNN_BN_ER\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c1273796e635f6f6e5f636865636b706f696e74948875622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bb020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f64617461944e8c026964944e8c0c73746f726167655f6d6f646594681b8c11436865636b706f696e7453746f726167659493944b01859452948c176c6f63616c5f746f5f72656d6f74655f706174685f666e944e8c076d657472696373947d948c076e6f64655f6970944e8c155f6d6f76655f696e73746561645f6f665f636f70799488756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_cl_agent_on_val_tasks\",\n  \"trial_id\": \"3c642_00001\",\n  \"config\": {\n    \"generic\": {\n      \"lr\": 0.001,\n      \"lradj\": \"step10\",\n      \"batch_size\": 32,\n      \"weight_decay\": 0\n    },\n    \"model\": {\n      \"feature_dim\": 128,\n      \"n_layers\": 4,\n      \"dropout\": 0\n    },\n    \"agent\": {}\n  },\n  \"_local_dir\": \"/disk2/lihuajian/TSCIL/result/ray_tune_results/class/har/CNN_BN_ER\",\n  \"evaluated_params\": {\n    \"generic/lradj\": \"step10\"\n  },\n  \"experiment_tag\": \"1_lradj=step10\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740100000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"end_avg_acc\": 84.04833333333335,\n    \"end_avg_fgt\": 4.487499999999997,\n    \"avg_cur_acc\": 87.04,\n    \"Acc_across_runs\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059507010000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d62756666657294939428969000000000000000000000000000594000000000000000000000000000000000d7a3703d0ae7574000000000000059400000000000000000a4703d0ad7e358407b14ae47e1ba5840f6285c8fc215454000000000000059400000000000000000000000000000000048e17a14ae575840295c8fc2f5e858400000000000000000ec51b81e85ab584052b81e85eb215540ec51b81e851b5440948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b024b034b0387948c014394749452942e\"\n    },\n    \"time_this_iter_s\": 308.5090374946594,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"3c642_00001\",\n    \"experiment_id\": \"13853cebda1e42c99726250ec20db2f8\",\n    \"date\": \"2024-05-06_20-12-53\",\n    \"timestamp\": 1714997573,\n    \"time_total_s\": 308.5090374946594,\n    \"pid\": 3962548,\n    \"hostname\": \"rinc1080ti-PR4764GW\",\n    \"node_ip\": \"114.212.87.168\",\n    \"config\": {\n      \"generic\": {\n        \"lr\": 0.001,\n        \"lradj\": \"step10\",\n        \"batch_size\": 32,\n        \"weight_decay\": 0\n      },\n      \"model\": {\n        \"feature_dim\": 128,\n        \"n_layers\": 4,\n        \"dropout\": 0\n      },\n      \"agent\": {}\n    },\n    \"time_since_restore\": 308.5090374946594,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"warmup_time\": 0.005312204360961914,\n    \"experiment_tag\": \"1_lradj=step10\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1714997573.2314787,\n  \"metric_analysis\": {\n    \"end_avg_acc\": {\n      \"max\": 84.04833333333335,\n      \"min\": 84.04833333333335,\n      \"avg\": 84.04833333333335,\n      \"last\": 84.04833333333335,\n      \"last-5-avg\": 84.04833333333335,\n      \"last-10-avg\": 84.04833333333335\n    },\n    \"end_avg_fgt\": {\n      \"max\": 4.487499999999997,\n      \"min\": 4.487499999999997,\n      \"avg\": 4.487499999999997,\n      \"last\": 4.487499999999997,\n      \"last-5-avg\": 4.487499999999997,\n      \"last-10-avg\": 4.487499999999997\n    },\n    \"avg_cur_acc\": {\n      \"max\": 87.04,\n      \"min\": 87.04,\n      \"avg\": 87.04,\n      \"last\": 87.04,\n      \"last-5-avg\": 87.04,\n      \"last-10-avg\": 87.04\n    },\n    \"time_this_iter_s\": {\n      \"max\": 308.5090374946594,\n      \"min\": 308.5090374946594,\n      \"avg\": 308.5090374946594,\n      \"last\": 308.5090374946594,\n      \"last-5-avg\": 308.5090374946594,\n      \"last-10-avg\": 308.5090374946594\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 308.5090374946594,\n      \"min\": 308.5090374946594,\n      \"avg\": 308.5090374946594,\n      \"last\": 308.5090374946594,\n      \"last-5-avg\": 308.5090374946594,\n      \"last-10-avg\": 308.5090374946594\n    },\n    \"time_since_restore\": {\n      \"max\": 308.5090374946594,\n      \"min\": 308.5090374946594,\n      \"avg\": 308.5090374946594,\n      \"last\": 308.5090374946594,\n      \"last-5-avg\": 308.5090374946594,\n      \"last-10-avg\": 308.5090374946594\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"warmup_time\": {\n      \"max\": 0.005312204360961914,\n      \"min\": 0.005312204360961914,\n      \"avg\": 0.005312204360961914,\n      \"last\": 0.005312204360961914,\n      \"last-5-avg\": 0.005312204360961914,\n      \"last-10-avg\": 0.005312204360961914\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"end_avg_acc\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243084c7eb1e4170355409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243084c7eb1e4170355409486945294612e\"\n      }\n    },\n    \"end_avg_fgt\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243083033333333f311409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243083033333333f311409486945294612e\"\n      }\n    },\n    \"avg_cur_acc\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308c3f5285c8fc255409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308c3f5285c8fc255409486945294612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474073482504800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474073482504800000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474073482504800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474073482504800000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474073482504800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474073482504800000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473f75c24000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473f75c24000000000612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1714997260.4816768,\n  \"relative_logdir\": \"3c642_00001_1_lradj=step10_2024-05-06_20-07-40\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"trial_name_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059571020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b014b5343087c006a009b005300944e85948c08747269616c5f69649485948c01749485948c312f6469736b322f6c696875616a69616e2f545343494c2f6578706572696d656e742f74756e655f616e645f6578702e7079948c083c6c616d6264613e944ba543020800942929749452947d94288c0b5f5f7061636b6167655f5f948c0a6578706572696d656e74948c085f5f6e616d655f5f948c176578706572696d656e742e74756e655f616e645f657870948c085f5f66696c655f5f948c312f6469736b322f6c696875616a69616e2f545343494c2f6578706572696d656e742f74756e655f616e645f6578702e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681b7d947d94286816680f8c0c5f5f7175616c6e616d655f5f948c2f74756e655f6879706572706172616d735f6f6e5f76616c5f7461736b732e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": \"3c642_00001\",\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"CNN_BN_ER\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c1273796e635f6f6e5f636865636b706f696e74948875622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bb020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f64617461944e8c026964944e8c0c73746f726167655f6d6f646594681b8c11436865636b706f696e7453746f726167659493944b01859452948c176c6f63616c5f746f5f72656d6f74655f706174685f666e944e8c076d657472696373947d948c076e6f64655f6970944e8c155f6d6f76655f696e73746561645f6f665f636f70799488756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_cl_agent_on_val_tasks\",\n  \"trial_id\": \"3c642_00000\",\n  \"config\": {\n    \"generic\": {\n      \"lr\": 0.001,\n      \"lradj\": \"TST\",\n      \"batch_size\": 32,\n      \"weight_decay\": 0\n    },\n    \"model\": {\n      \"feature_dim\": 128,\n      \"n_layers\": 4,\n      \"dropout\": 0\n    },\n    \"agent\": {}\n  },\n  \"_local_dir\": \"/disk2/lihuajian/TSCIL/result/ray_tune_results/class/har/CNN_BN_ER\",\n  \"evaluated_params\": {\n    \"generic/lradj\": \"TST\"\n  },\n  \"experiment_tag\": \"0_lradj=TST\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740100000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"end_avg_acc\": 80.60499999999999,\n    \"end_avg_fgt\": 13.265,\n    \"avg_cur_acc\": 88.48833333333334,\n    \"Acc_across_runs\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059507010000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d6275666665729493942896900000000000000000000000000059400000000000000000000000000000000066666666662656408fc2f5285c8f5740000000000000000048e17a14aec758400000000000005940295c8fc2f5c84340000000000000594000000000000000000000000000000000000000000000594048e17a14ae4758400000000000000000d7a3703d0a7757400ad7a3703d8a49400000000000005940948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b024b034b0387948c014394749452942e\"\n    },\n    \"time_this_iter_s\": 398.9986412525177,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"3c642_00000\",\n    \"experiment_id\": \"302a5c6f1b7e4c12a2efc30b772fd884\",\n    \"date\": \"2024-05-06_20-14-23\",\n    \"timestamp\": 1714997663,\n    \"time_total_s\": 398.9986412525177,\n    \"pid\": 3962546,\n    \"hostname\": \"rinc1080ti-PR4764GW\",\n    \"node_ip\": \"114.212.87.168\",\n    \"config\": {\n      \"generic\": {\n        \"lr\": 0.001,\n        \"lradj\": \"TST\",\n        \"batch_size\": 32,\n        \"weight_decay\": 0\n      },\n      \"model\": {\n        \"feature_dim\": 128,\n        \"n_layers\": 4,\n        \"dropout\": 0\n      },\n      \"agent\": {}\n    },\n    \"time_since_restore\": 398.9986412525177,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"warmup_time\": 0.005392789840698242,\n    \"experiment_tag\": \"0_lradj=TST\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1714997663.8465679,\n  \"metric_analysis\": {\n    \"end_avg_acc\": {\n      \"max\": 80.60499999999999,\n      \"min\": 80.60499999999999,\n      \"avg\": 80.60499999999999,\n      \"last\": 80.60499999999999,\n      \"last-5-avg\": 80.60499999999999,\n      \"last-10-avg\": 80.60499999999999\n    },\n    \"end_avg_fgt\": {\n      \"max\": 13.265,\n      \"min\": 13.265,\n      \"avg\": 13.265,\n      \"last\": 13.265,\n      \"last-5-avg\": 13.265,\n      \"last-10-avg\": 13.265\n    },\n    \"avg_cur_acc\": {\n      \"max\": 88.48833333333334,\n      \"min\": 88.48833333333334,\n      \"avg\": 88.48833333333334,\n      \"last\": 88.48833333333334,\n      \"last-5-avg\": 88.48833333333334,\n      \"last-10-avg\": 88.48833333333334\n    },\n    \"time_this_iter_s\": {\n      \"max\": 398.9986412525177,\n      \"min\": 398.9986412525177,\n      \"avg\": 398.9986412525177,\n      \"last\": 398.9986412525177,\n      \"last-5-avg\": 398.9986412525177,\n      \"last-10-avg\": 398.9986412525177\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 398.9986412525177,\n      \"min\": 398.9986412525177,\n      \"avg\": 398.9986412525177,\n      \"last\": 398.9986412525177,\n      \"last-5-avg\": 398.9986412525177,\n      \"last-10-avg\": 398.9986412525177\n    },\n    \"time_since_restore\": {\n      \"max\": 398.9986412525177,\n      \"min\": 398.9986412525177,\n      \"avg\": 398.9986412525177,\n      \"last\": 398.9986412525177,\n      \"last-5-avg\": 398.9986412525177,\n      \"last-10-avg\": 398.9986412525177\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"warmup_time\": {\n      \"max\": 0.005392789840698242,\n      \"min\": 0.005392789840698242,\n      \"avg\": 0.005392789840698242,\n      \"last\": 0.005392789840698242,\n      \"last-5-avg\": 0.005392789840698242,\n      \"last-10-avg\": 0.005392789840698242\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"end_avg_acc\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243081e85eb51b82654409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243081e85eb51b82654409486945294612e\"\n      }\n    },\n    \"end_avg_fgt\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430848e17a14ae872a409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430848e17a14ae872a409486945294612e\"\n      }\n    },\n    \"avg_cur_acc\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308a80d74da401f56409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308a80d74da401f56409486945294612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474078effa6f400000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474078effa6f400000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474078effa6f400000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474078effa6f400000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474078effa6f400000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474078effa6f400000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473f7616c000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473f7616c000000000612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1714997260.4723492,\n  \"relative_logdir\": \"3c642_00000_0_lradj=TST_2024-05-06_20-07-40\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"trial_name_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059571020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b014b5343087c006a009b005300944e85948c08747269616c5f69649485948c01749485948c312f6469736b322f6c696875616a69616e2f545343494c2f6578706572696d656e742f74756e655f616e645f6578702e7079948c083c6c616d6264613e944ba543020800942929749452947d94288c0b5f5f7061636b6167655f5f948c0a6578706572696d656e74948c085f5f6e616d655f5f948c176578706572696d656e742e74756e655f616e645f657870948c085f5f66696c655f5f948c312f6469736b322f6c696875616a69616e2f545343494c2f6578706572696d656e742f74756e655f616e645f6578702e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681b7d947d94286816680f8c0c5f5f7175616c6e616d655f5f948c2f74756e655f6879706572706172616d735f6f6e5f76616c5f7461736b732e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": \"3c642_00000\",\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"CNN_BN_ER\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c1273796e635f6f6e5f636865636b706f696e74948875622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bb020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f64617461944e8c026964944e8c0c73746f726167655f6d6f646594681b8c11436865636b706f696e7453746f726167659493944b01859452948c176c6f63616c5f746f5f72656d6f74655f706174685f666e944e8c076d657472696373947d948c076e6f64655f6970944e8c155f6d6f76655f696e73746561645f6f665f636f70799488756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}"
  ],
  "runner_data": {
    "_insufficient_resources_manager": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "80059596000000000000008c317261792e74756e652e657865637574696f6e2e696e73756666696369656e745f7265736f75726365735f6d616e61676572948c1d5f496e73756666696369656e745265736f75726365734d616e616765729493942981947d94288c185f6e6f5f72756e6e696e675f747269616c735f73696e6365944affffffff8c0f5f6c6173745f747269616c5f6e756d944affffffff75622e"
    },
    "_max_pending_trials": 35,
    "_metric": null,
    "_total_time": 1899.7061958312988,
    "_iteration": 119,
    "_has_errored": false,
    "_fail_fast": false,
    "_print_trial_errors": true,
    "_server_port": null,
    "_cached_trial_decisions": {},
    "_queued_trial_decisions": {},
    "_should_stop_experiment": false,
    "_stopper": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "8005952c000000000000008c157261792e74756e652e73746f707065722e6e6f6f70948c0b4e6f6f7053746f707065729493942981942e"
    },
    "_resumed": false,
    "_start_time": 1714997260.2652512,
    "_last_checkpoint_time": -Infinity,
    "_session_str": "2024-05-06_20-07-40",
    "checkpoint_file": "/disk2/lihuajian/TSCIL/result/ray_tune_results/class/har/CNN_BN_ER/experiment_state-2024-05-06_20-07-40.json",
    "_checkpoint_period": "auto",
    "_trial_checkpoint_config": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "800595ab000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c00948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e"
    },
    "launch_web_server": false
  },
  "stats": {
    "start_time": 1714997260.2652512,
    "timestamp": 1714997813.9739318
  }
}