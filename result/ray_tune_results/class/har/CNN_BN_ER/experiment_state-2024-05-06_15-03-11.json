{
  "checkpoints": [
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_cl_agent_on_val_tasks\",\n  \"trial_id\": \"b34c8_00001\",\n  \"config\": {\n    \"generic\": {\n      \"lr\": 0.001,\n      \"lradj\": \"step10\",\n      \"batch_size\": 32,\n      \"weight_decay\": 0\n    },\n    \"model\": {\n      \"feature_dim\": 128,\n      \"n_layers\": 4,\n      \"dropout\": 0\n    },\n    \"agent\": {}\n  },\n  \"_local_dir\": \"/disk2/lihuajian/TSCIL/result/ray_tune_results/class/har/CNN_BN_ER\",\n  \"evaluated_params\": {\n    \"generic/lradj\": \"step10\"\n  },\n  \"experiment_tag\": \"1_lradj=step10\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740100000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"end_avg_acc\": 90.315,\n    \"end_avg_fgt\": 3.057500000000001,\n    \"avg_cur_acc\": 92.35333333333334,\n    \"Acc_across_runs\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059507010000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d627566666572949394289690000000000000000000000000005940000000000000000000000000000000000000000000803740000000000000594000000000000000000000000000a05840333333333383584014ae47e17a3451400000000000005940000000000000000000000000000000000000000000001640000000000000594000000000000000000000000000c05840ae47e17a140e57403333333333535540948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b024b034b0387948c014394749452942e\"\n    },\n    \"time_this_iter_s\": 303.2118110656738,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"b34c8_00001\",\n    \"experiment_id\": \"8e8fbe16cc384fffbc0a60d28f57c81e\",\n    \"date\": \"2024-05-06_15-14-53\",\n    \"timestamp\": 1714979693,\n    \"time_total_s\": 303.2118110656738,\n    \"pid\": 3365038,\n    \"hostname\": \"rinc1080ti-PR4764GW\",\n    \"node_ip\": \"114.212.87.168\",\n    \"config\": {\n      \"generic\": {\n        \"lr\": 0.001,\n        \"lradj\": \"step10\",\n        \"batch_size\": 32,\n        \"weight_decay\": 0\n      },\n      \"model\": {\n        \"feature_dim\": 128,\n        \"n_layers\": 4,\n        \"dropout\": 0\n      },\n      \"agent\": {}\n    },\n    \"time_since_restore\": 303.2118110656738,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"warmup_time\": 0.004407167434692383,\n    \"experiment_tag\": \"1_lradj=step10\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1714979693.0884888,\n  \"metric_analysis\": {\n    \"end_avg_acc\": {\n      \"max\": 90.315,\n      \"min\": 90.315,\n      \"avg\": 90.315,\n      \"last\": 90.315,\n      \"last-5-avg\": 90.315,\n      \"last-10-avg\": 90.315\n    },\n    \"end_avg_fgt\": {\n      \"max\": 3.057500000000001,\n      \"min\": 3.057500000000001,\n      \"avg\": 3.057500000000001,\n      \"last\": 3.057500000000001,\n      \"last-5-avg\": 3.057500000000001,\n      \"last-10-avg\": 3.057500000000001\n    },\n    \"avg_cur_acc\": {\n      \"max\": 92.35333333333334,\n      \"min\": 92.35333333333334,\n      \"avg\": 92.35333333333334,\n      \"last\": 92.35333333333334,\n      \"last-5-avg\": 92.35333333333334,\n      \"last-10-avg\": 92.35333333333334\n    },\n    \"time_this_iter_s\": {\n      \"max\": 303.2118110656738,\n      \"min\": 303.2118110656738,\n      \"avg\": 303.2118110656738,\n      \"last\": 303.2118110656738,\n      \"last-5-avg\": 303.2118110656738,\n      \"last-10-avg\": 303.2118110656738\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 303.2118110656738,\n      \"min\": 303.2118110656738,\n      \"avg\": 303.2118110656738,\n      \"last\": 303.2118110656738,\n      \"last-5-avg\": 303.2118110656738,\n      \"last-10-avg\": 303.2118110656738\n    },\n    \"time_since_restore\": {\n      \"max\": 303.2118110656738,\n      \"min\": 303.2118110656738,\n      \"avg\": 303.2118110656738,\n      \"last\": 303.2118110656738,\n      \"last-5-avg\": 303.2118110656738,\n      \"last-10-avg\": 303.2118110656738\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"warmup_time\": {\n      \"max\": 0.004407167434692383,\n      \"min\": 0.004407167434692383,\n      \"avg\": 0.004407167434692383,\n      \"last\": 0.004407167434692383,\n      \"last-5-avg\": 0.004407167434692383,\n      \"last-10-avg\": 0.004407167434692383\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"end_avg_acc\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243085c8fc2f5289456409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243085c8fc2f5289456409486945294612e\"\n      }\n    },\n    \"end_avg_fgt\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308f8285c8fc27508409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308f8285c8fc27508409486945294612e\"\n      }\n    },\n    \"avg_cur_acc\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430837d069039d1657409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430837d069039d1657409486945294612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474072f36394000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474072f36394000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474072f36394000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474072f36394000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474072f36394000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474072f36394000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473f720d4000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473f720d4000000000612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1714979389.864278,\n  \"relative_logdir\": \"b34c8_00001_1_lradj=step10_2024-05-06_15-09-49\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"trial_name_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059571020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b014b5343087c006a009b005300944e85948c08747269616c5f69649485948c01749485948c312f6469736b322f6c696875616a69616e2f545343494c2f6578706572696d656e742f74756e655f616e645f6578702e7079948c083c6c616d6264613e944ba543020800942929749452947d94288c0b5f5f7061636b6167655f5f948c0a6578706572696d656e74948c085f5f6e616d655f5f948c176578706572696d656e742e74756e655f616e645f657870948c085f5f66696c655f5f948c312f6469736b322f6c696875616a69616e2f545343494c2f6578706572696d656e742f74756e655f616e645f6578702e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681b7d947d94286816680f8c0c5f5f7175616c6e616d655f5f948c2f74756e655f6879706572706172616d735f6f6e5f76616c5f7461736b732e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": \"b34c8_00001\",\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"CNN_BN_ER\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c1273796e635f6f6e5f636865636b706f696e74948875622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bb020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f64617461944e8c026964944e8c0c73746f726167655f6d6f646594681b8c11436865636b706f696e7453746f726167659493944b01859452948c176c6f63616c5f746f5f72656d6f74655f706174685f666e944e8c076d657472696373947d948c076e6f64655f6970944e8c155f6d6f76655f696e73746561645f6f665f636f70799488756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_cl_agent_on_val_tasks\",\n  \"trial_id\": \"b34c8_00000\",\n  \"config\": {\n    \"generic\": {\n      \"lr\": 0.001,\n      \"lradj\": \"TST\",\n      \"batch_size\": 32,\n      \"weight_decay\": 0\n    },\n    \"model\": {\n      \"feature_dim\": 128,\n      \"n_layers\": 4,\n      \"dropout\": 0\n    },\n    \"agent\": {}\n  },\n  \"_local_dir\": \"/disk2/lihuajian/TSCIL/result/ray_tune_results/class/har/CNN_BN_ER\",\n  \"evaluated_params\": {\n    \"generic/lradj\": \"TST\"\n  },\n  \"experiment_tag\": \"0_lradj=TST\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740100000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"end_avg_acc\": 83.25500000000001,\n    \"end_avg_fgt\": 1.4600000000000009,\n    \"avg_cur_acc\": 84.22833333333334,\n    \"Acc_across_runs\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059507010000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d6275666665729493942896900000000000000000000000000059400000000000000000000000000000000000000000002053400000000000005940000000000000000000000000000059403333333333a35740295c8fc2f5484e400000000000005940000000000000000000000000000000000000000000003340000000000000594000000000000000000000000000005940d7a3703d0ae758406666666666664640948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b024b034b0387948c014394749452942e\"\n    },\n    \"time_this_iter_s\": 393.1862061023712,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"b34c8_00000\",\n    \"experiment_id\": \"8e8fbe16cc384fffbc0a60d28f57c81e\",\n    \"date\": \"2024-05-06_15-09-49\",\n    \"timestamp\": 1714979389,\n    \"time_total_s\": 393.1862061023712,\n    \"pid\": 3365038,\n    \"hostname\": \"rinc1080ti-PR4764GW\",\n    \"node_ip\": \"114.212.87.168\",\n    \"config\": {\n      \"generic\": {\n        \"lr\": 0.001,\n        \"lradj\": \"TST\",\n        \"batch_size\": 32,\n        \"weight_decay\": 0\n      },\n      \"model\": {\n        \"feature_dim\": 128,\n        \"n_layers\": 4,\n        \"dropout\": 0\n      },\n      \"agent\": {}\n    },\n    \"time_since_restore\": 393.1862061023712,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"warmup_time\": 0.004407167434692383,\n    \"experiment_tag\": \"0_lradj=TST\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1714979389.6018693,\n  \"metric_analysis\": {\n    \"end_avg_acc\": {\n      \"max\": 83.25500000000001,\n      \"min\": 83.25500000000001,\n      \"avg\": 83.25500000000001,\n      \"last\": 83.25500000000001,\n      \"last-5-avg\": 83.25500000000001,\n      \"last-10-avg\": 83.25500000000001\n    },\n    \"end_avg_fgt\": {\n      \"max\": 1.4600000000000009,\n      \"min\": 1.4600000000000009,\n      \"avg\": 1.4600000000000009,\n      \"last\": 1.4600000000000009,\n      \"last-5-avg\": 1.4600000000000009,\n      \"last-10-avg\": 1.4600000000000009\n    },\n    \"avg_cur_acc\": {\n      \"max\": 84.22833333333334,\n      \"min\": 84.22833333333334,\n      \"avg\": 84.22833333333334,\n      \"last\": 84.22833333333334,\n      \"last-5-avg\": 84.22833333333334,\n      \"last-10-avg\": 84.22833333333334\n    },\n    \"time_this_iter_s\": {\n      \"max\": 393.1862061023712,\n      \"min\": 393.1862061023712,\n      \"avg\": 393.1862061023712,\n      \"last\": 393.1862061023712,\n      \"last-5-avg\": 393.1862061023712,\n      \"last-10-avg\": 393.1862061023712\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 393.1862061023712,\n      \"min\": 393.1862061023712,\n      \"avg\": 393.1862061023712,\n      \"last\": 393.1862061023712,\n      \"last-5-avg\": 393.1862061023712,\n      \"last-10-avg\": 393.1862061023712\n    },\n    \"time_since_restore\": {\n      \"max\": 393.1862061023712,\n      \"min\": 393.1862061023712,\n      \"avg\": 393.1862061023712,\n      \"last\": 393.1862061023712,\n      \"last-5-avg\": 393.1862061023712,\n      \"last-10-avg\": 393.1862061023712\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"warmup_time\": {\n      \"max\": 0.004407167434692383,\n      \"min\": 0.004407167434692383,\n      \"avg\": 0.004407167434692383,\n      \"last\": 0.004407167434692383,\n      \"last-5-avg\": 0.004407167434692383,\n      \"last-10-avg\": 0.004407167434692383\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"end_avg_acc\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308b91e85eb51d054409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308b91e85eb51d054409486945294612e\"\n      }\n    },\n    \"end_avg_fgt\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308608fc2f5285cf73f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308608fc2f5285cf73f9486945294612e\"\n      }\n    },\n    \"avg_cur_acc\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430837d069039d0e55409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430837d069039d0e55409486945294612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447407892fab3400000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447407892fab3400000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447407892fab3400000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447407892fab3400000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447407892fab3400000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447407892fab3400000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473f720d4000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473f720d4000000000612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1714978991.5295026,\n  \"relative_logdir\": \"b34c8_00000_0_lradj=TST_2024-05-06_15-03-11\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"trial_name_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059571020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b014b5343087c006a009b005300944e85948c08747269616c5f69649485948c01749485948c312f6469736b322f6c696875616a69616e2f545343494c2f6578706572696d656e742f74756e655f616e645f6578702e7079948c083c6c616d6264613e944ba543020800942929749452947d94288c0b5f5f7061636b6167655f5f948c0a6578706572696d656e74948c085f5f6e616d655f5f948c176578706572696d656e742e74756e655f616e645f657870948c085f5f66696c655f5f948c312f6469736b322f6c696875616a69616e2f545343494c2f6578706572696d656e742f74756e655f616e645f6578702e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681b7d947d94286816680f8c0c5f5f7175616c6e616d655f5f948c2f74756e655f6879706572706172616d735f6f6e5f76616c5f7461736b732e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": \"b34c8_00000\",\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"CNN_BN_ER\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c1273796e635f6f6e5f636865636b706f696e74948875622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bb020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f64617461944e8c026964944e8c0c73746f726167655f6d6f646594681b8c11436865636b706f696e7453746f726167659493944b01859452948c176c6f63616c5f746f5f72656d6f74655f706174685f666e944e8c076d657472696373947d948c076e6f64655f6970944e8c155f6d6f76655f696e73746561645f6f665f636f70799488756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"tune_cl_agent_on_val_tasks\",\n  \"trial_id\": \"b34c8_00002\",\n  \"config\": {\n    \"generic\": {\n      \"lr\": 0.001,\n      \"lradj\": \"step15\",\n      \"batch_size\": 32,\n      \"weight_decay\": 0\n    },\n    \"model\": {\n      \"feature_dim\": 128,\n      \"n_layers\": 4,\n      \"dropout\": 0\n    },\n    \"agent\": {}\n  },\n  \"_local_dir\": \"/disk2/lihuajian/TSCIL/result/ray_tune_results/class/har/CNN_BN_ER\",\n  \"evaluated_params\": {\n    \"generic/lradj\": \"step15\"\n  },\n  \"experiment_tag\": \"2_lradj=step15\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740100000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"end_avg_acc\": 81.85833333333332,\n    \"end_avg_fgt\": 16.37,\n    \"avg_cur_acc\": 92.77166666666668,\n    \"Acc_across_runs\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059507010000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d627566666572949394289690000000000000000000000000005940000000000000000000000000000000000000000000001440000000000000594000000000000000000000000000405840666666666666454085eb51b81ed55140000000000000594000000000000000000000000000000000000000000000f03f000000000000594000000000000000000000000000c05840ae47e17a14ee57403333333333535540948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b024b034b0387948c014394749452942e\"\n    },\n    \"time_this_iter_s\": 226.6010193824768,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"b34c8_00002\",\n    \"experiment_id\": \"8e8fbe16cc384fffbc0a60d28f57c81e\",\n    \"date\": \"2024-05-06_15-18-39\",\n    \"timestamp\": 1714979919,\n    \"time_total_s\": 226.6010193824768,\n    \"pid\": 3365038,\n    \"hostname\": \"rinc1080ti-PR4764GW\",\n    \"node_ip\": \"114.212.87.168\",\n    \"config\": {\n      \"generic\": {\n        \"lr\": 0.001,\n        \"lradj\": \"step15\",\n        \"batch_size\": 32,\n        \"weight_decay\": 0\n      },\n      \"model\": {\n        \"feature_dim\": 128,\n        \"n_layers\": 4,\n        \"dropout\": 0\n      },\n      \"agent\": {}\n    },\n    \"time_since_restore\": 226.6010193824768,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"warmup_time\": 0.004407167434692383,\n    \"experiment_tag\": \"2_lradj=step15\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1714979919.7444193,\n  \"metric_analysis\": {\n    \"end_avg_acc\": {\n      \"max\": 81.85833333333332,\n      \"min\": 81.85833333333332,\n      \"avg\": 81.85833333333332,\n      \"last\": 81.85833333333332,\n      \"last-5-avg\": 81.85833333333332,\n      \"last-10-avg\": 81.85833333333332\n    },\n    \"end_avg_fgt\": {\n      \"max\": 16.37,\n      \"min\": 16.37,\n      \"avg\": 16.37,\n      \"last\": 16.37,\n      \"last-5-avg\": 16.37,\n      \"last-10-avg\": 16.37\n    },\n    \"avg_cur_acc\": {\n      \"max\": 92.77166666666668,\n      \"min\": 92.77166666666668,\n      \"avg\": 92.77166666666668,\n      \"last\": 92.77166666666668,\n      \"last-5-avg\": 92.77166666666668,\n      \"last-10-avg\": 92.77166666666668\n    },\n    \"time_this_iter_s\": {\n      \"max\": 226.6010193824768,\n      \"min\": 226.6010193824768,\n      \"avg\": 226.6010193824768,\n      \"last\": 226.6010193824768,\n      \"last-5-avg\": 226.6010193824768,\n      \"last-10-avg\": 226.6010193824768\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 226.6010193824768,\n      \"min\": 226.6010193824768,\n      \"avg\": 226.6010193824768,\n      \"last\": 226.6010193824768,\n      \"last-5-avg\": 226.6010193824768,\n      \"last-10-avg\": 226.6010193824768\n    },\n    \"time_since_restore\": {\n      \"max\": 226.6010193824768,\n      \"min\": 226.6010193824768,\n      \"avg\": 226.6010193824768,\n      \"last\": 226.6010193824768,\n      \"last-5-avg\": 226.6010193824768,\n      \"last-10-avg\": 226.6010193824768\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"warmup_time\": {\n      \"max\": 0.004407167434692383,\n      \"min\": 0.004407167434692383,\n      \"avg\": 0.004407167434692383,\n      \"last\": 0.004407167434692383,\n      \"last-5-avg\": 0.004407167434692383,\n      \"last-10-avg\": 0.004407167434692383\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"end_avg_acc\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308eeeeeeeeee7654409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308eeeeeeeeee7654409486945294612e\"\n      }\n    },\n    \"end_avg_fgt\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243081f85eb51b85e30409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243081f85eb51b85e30409486945294612e\"\n      }\n    },\n    \"avg_cur_acc\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308ca2f96fc623157409486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308ca2f96fc623157409486945294612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447406c533b8d000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447406c533b8d000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447406c533b8d000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447406c533b8d000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447406c533b8d000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447406c533b8d000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473f720d4000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473f720d4000000000612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1714979693.1288683,\n  \"relative_logdir\": \"b34c8_00002_2_lradj=step15_2024-05-06_15-14-53\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"trial_name_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059571020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b014b5343087c006a009b005300944e85948c08747269616c5f69649485948c01749485948c312f6469736b322f6c696875616a69616e2f545343494c2f6578706572696d656e742f74756e655f616e645f6578702e7079948c083c6c616d6264613e944ba543020800942929749452947d94288c0b5f5f7061636b6167655f5f948c0a6578706572696d656e74948c085f5f6e616d655f5f948c176578706572696d656e742e74756e655f616e645f657870948c085f5f66696c655f5f948c312f6469736b322f6c696875616a69616e2f545343494c2f6578706572696d656e742f74756e655f616e645f6578702e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681b7d947d94286816680f8c0c5f5f7175616c6e616d655f5f948c2f74756e655f6879706572706172616d735f6f6e5f76616c5f7461736b732e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468178c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": \"b34c8_00002\",\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"CNN_BN_ER\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c1273796e635f6f6e5f636865636b706f696e74948875622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bb020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f64617461944e8c026964944e8c0c73746f726167655f6d6f646594681b8c11436865636b706f696e7453746f726167659493944b01859452948c176c6f63616c5f746f5f72656d6f74655f706174685f666e944e8c076d657472696373947d948c076e6f64655f6970944e8c155f6d6f76655f696e73746561645f6f665f636f70799488756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}"
  ],
  "runner_data": {
    "_insufficient_resources_manager": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "80059596000000000000008c317261792e74756e652e657865637574696f6e2e696e73756666696369656e745f7265736f75726365735f6d616e61676572948c1d5f496e73756666696369656e745265736f75726365734d616e616765729493942981947d94288c185f6e6f5f72756e6e696e675f747269616c735f73696e6365944affffffff8c0f5f6c6173745f747269616c5f6e756d944affffffff75622e"
    },
    "_max_pending_trials": 35,
    "_metric": null,
    "_total_time": 1845.9980731010437,
    "_iteration": 192,
    "_has_errored": false,
    "_fail_fast": false,
    "_print_trial_errors": true,
    "_server_port": null,
    "_cached_trial_decisions": {},
    "_queued_trial_decisions": {},
    "_should_stop_experiment": false,
    "_stopper": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "8005952c000000000000008c157261792e74756e652e73746f707065722e6e6f6f70948c0b4e6f6f7053746f707065729493942981942e"
    },
    "_resumed": false,
    "_start_time": 1714978991.4130023,
    "_last_checkpoint_time": -Infinity,
    "_session_str": "2024-05-06_15-03-11",
    "checkpoint_file": "/disk2/lihuajian/TSCIL/result/ray_tune_results/class/har/CNN_BN_ER/experiment_state-2024-05-06_15-03-11.json",
    "_checkpoint_period": "auto",
    "_trial_checkpoint_config": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "800595ab000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c00948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948975622e"
    },
    "launch_web_server": false
  },
  "stats": {
    "start_time": 1714978991.4130023,
    "timestamp": 1714979913.3437252
  }
}